hundreds
(sapply(1:1000, function(i) l[[i]][1]))
(sapply(1:1000, function(i) l[[i]][1])) *1e6
(sapply(1:1000, function(i) l[[i]][2]) / 500) * 1e6
(sapply(1:1000, function(i) l[[i]][3]) / 1000) * 1e6
(sapply(1:1000, function(i) l[[i]][4]) / 10000) * 1e6
(sapply(1:1000, function(i) l[[i]][1])) *1e6
(sapply(1:1000, function(i) l[[i]][2]) / 500) * 1e6
(sapply(1:1000, function(i) l[[i]][3]) / 1000) * 1e6
(sapply(1:1000, function(i) l[[i]][4]) / 10000) * 1e6
(sapply(1:1000, function(i) l[[i]][1])) *1e6
(sapply(1:1000, function(i) l[[i]][1]) / 100) *1e6
(sapply(1:1000, function(i) l[[i]][2]) / 500) * 1e6
(sapply(1:1000, function(i) l[[i]][3]) / 1000) * 1e6
(sapply(1:1000, function(i) l[[i]][4]) / 10000) * 1e6
hundreds_top <- (sapply(1:1000, function(i) l[[i]][1]) / 100) *1e6
fivehundreds_top <-(sapply(1:1000, function(i) l[[i]][2]) / 500) * 1e6
thousands_top <- (sapply(1:1000, function(i) l[[i]][3]) / 1000) * 1e6
tenthousands_top <- (sapply(1:1000, function(i) l[[i]][4]) / 10000) * 1e6
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
# Imagine the distribution remains unchanged:
# 10 different types, 2046 types in 1 million tokens
# (following a Zipfian distribution)
hyph <- c(rep("a", 2), rep("b", 4), rep("c", 8), rep("d", 16), rep("e", 32),
rep("f", 64), rep("g", 128), rep("h", 256), rep("i", 512), rep("j", 1024))
all <- c(rep("nohyphen", 1e6-2046), hyph)
set.seed(100)
all <- sample(all, length(all))
hundred <- sample(all, 100)
thousand <- sample(all, 1000)
tenthousand <- sample(all, 10000)
length(which(hundred!="nohyphen"))
length(which(thousand!="nohyphen"))
length(which(tenthousand!="nohyphen"))
# repeat simulation multiple times
set.seed(1985)
hundreds <- lapply(1:1000, function(x) sample(all, 100))
fivehundreds <- lapply(1:1000, function(x) sample(all, 500))
thousands <- lapply(1:1000, function(x) sample(all, 1000))
tenthousands <- lapply(1:1000, function(x) sample(all, 10000))
# sample all "hyphenated compounds" that occur at least five times
# if we take all four samples together, then get abs.
# frequency in each corpus; do the same for all "hyphenated compounds"
l <- list()
l2 <- list()
for(i in 1:1000) {
x <- c(hundreds[[i]], fivehundreds[[i]], thousands[[i]], tenthousands[[i]])
t <- table(x[which(x != "nohyphen")])
t1 <- rownames(t[which(t >= 5)])
# freq. >= 5:
l[[i]] <- c(
length(which(hundreds[[i]] %in% t1)),
length(which(fivehundreds[[i]] %in% t1)),
length(which(thousands[[i]] %in% t1)),
length(which(tenthousands[[i]] %in% t1))
)
# all:
l2[[i]] <- c(
length(which(hundreds[[i]] %in% letters)),
length(which(fivehundreds[[i]] %in% letters)),
length(which(thousands[[i]] %in% letters)),
length(which(tenthousands[[i]] %in% letters))
)
}
hundreds_all <- (sapply(1:1000, function(i) l2[[i]][1]) / 100) *1e6
fivehundreds_all <-(sapply(1:1000, function(i) l2[[i]][2]) / 500) * 1e6
thousands_all <- (sapply(1:1000, function(i) l2[[i]][3]) / 1000) * 1e6
tenthousands_all <- (sapply(1:1000, function(i) l2[[i]][4]) / 10000) * 1e6
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
abline(2046)
abline(h = 2046)
abline(h = 2046, lty = 2)
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
abline(h = 2046, lty = 2)
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
abline(h = 2046, lty = 2)
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
abline(h = 2046, lty = 2)
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
abline(h = 2046, lty = 2)
main("all hyphenated compounds")
title("all hyphenated compounds")
title("only hyphenated compounds with \n overall frequency >= 5")
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
abline(h = 2046, lty = 2)
title("only hyphenated compounds with \n overall frequency >= 5")
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
abline(h = 2046, lty = 2)
title("all hyphenated compounds")
text(x = 0.1, y = 2060, "actual frequency", cex = 2)
text(x = 0.1, y = 2060, "actual frequency", cex = 0.6)
text(x = 1, y = 2060, "actual frequency", cex = 0.6)
text(x = 1, y = 2070, "actual frequency", cex = 0.8)
text(x = 1, y = 2150, "actual frequency", cex = 0.8)
text(x = 1, y = 2550, "actual frequency", cex = 0.8)
boxplot(list(hundreds_all, fivehundreds_all, thousands_all,
tenthousands_all))
abline(h = 2046, lty = 2)
text(x = 1, y = 2550, "actual frequency", cex = 0.8)
title("all hyphenated compounds")
boxplot(list(hundreds_top, fivehundreds_top, thousands_top,
tenthousands_top))
abline(h = 2046, lty = 2)
text(x = 1, y = 2550, "actual frequency", cex = 0.8)
title("only hyphenated compounds with \n overall frequency >= 5")
?library
lib.oc
lib.loc
lib.loc()
?abs
?assocplot
write.table(readLines("https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=newssearch&cd=&cad=rja&uact=8&ved=0ahUKEwjn5vGA_cTpAhUNqJ4KHcdOAYcQqQIIdygAMBE&url=https%3A%2F%2Fwww.zeit.de%2Fkultur%2F2020-04%2Fumgang-coronavirus-wolfgang-schaeuble-diskussionskultur&usg=AOvVaw2Gf4OgANBqvApRBDoYdw8C"), file = "test.html", quote = F, row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de%2Fkultur%2F2020-04%2Fumgang-coronavirus-wolfgang-schaeuble-diskussionskultur&usg=AOvVaw2Gf4OgANBqvApRBDoYdw8C"), file = "test.html", quote = F, row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de/kultur/2020-04/umgang-coronavirus-wolfgang-schaeuble-diskussionskultur&usg=AOvVaw2Gf4OgANBqvApRBDoYdw8C"), file = "test.html", quote = F, row.names = F, col.names = F)
?assocplot
write.table(readLines("https://bit.ly/2WZBi7B"), col.names = F, row.names = F, quote = F)
write.table(readLines("https://bit.ly/2WZBi7B"), "test.html", col.names = F, row.names = F, quote = F)
write.table(readLines("https://www.zeit.de/kultur/2020-04/christian-drosten-virologe-coronavirus-deutschland-medienkritik/komplettansicht"), file = "test.html", row.names = F, col.names = F, quote = F)
citation()
citation("tidyverse")
7302.92/608.58
9*52
280+56+84
install.packages(c("mapview", "tmap"))
devtools::install_github("hartmast/wizard")
plot(c(1:100), c(1:100), type = "l")
plot(c(1:100), c(1:100), type = "l", ylab = "Years lived", xlab = "Age")
plot(c(1:100), c(1:100), type = "l", ylab = "Years lived", xlab = "Age",
col = "red", lwd = 2)
plot(c(30:100), c(30:100), type = "l", ylab = "Years lived", xlab = "Age",
col = "red", lwd = 2)
?read.csv
paste0(sample(c(1:10, [A-Z], [a-z]), 18))
?sample
paste0(sample(c(1:10, [A-Z], [a-z]), 18), replace = T)
c(c(1:10), [A-Z])
c(c(1:10), LETTERS)
c(c(1:10), LETTERS, letters)
sample(c(c(1:10), LETTERS, letters), 20)
paste0(sample(c(c(1:10), LETTERS, letters), 20))
paste0(sample(c(c(1:10), LETTERS, letters), 20), sep="")
paste0(sample(c(c(1:10), LETTERS, letters), 20), collapse="")
14/2936282
1/1
1/1.1
write.table(readLines("https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjNhZb8qrbqAhVRaRUIHU95A4gQFjAMegQIGhAB&url=https%3A%2F%2Fwww.zeit.de%2Fkultur%2F2020-06%2Fcancel-culture-struktureller-rassismus-kolonialismus-popkultur&usg=AOvVaw0IrfR1cTAXOMSSqM5AIFQJ"), quote = F,row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de/%2Fkultur%2F2020-06%2Fcancel-culture-struktureller-rassismus-kolonialismus-popkultur&usg=AOvVaw0IrfR1cTAXOMSSqM5AIFQJ"), quote = F,row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de/kultur/2020/cancel-culture-struktureller-rassismus-kolonialismus-popkultur&usg=AOvVaw0IrfR1cTAXOMSSqM5AIFQJ"), quote = F,row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de/kultur/2020-06/cancel-culture-struktureller-rassismus-kolonialismus-popkultur/komplettansicht"), quote = F,row.names = F, col.names = F)
write.table(readLines("https://www.zeit.de/kultur/2020-06/cancel-culture-struktureller-rassismus-kolonialismus-popkultur/komplettansicht"), quote = F,row.names = F, col.names = F, file = "test.html")
library(devtools)
library(concordances)
?getNSE
d <- getNSE("gedownloadet.xml", xml = TRUE, tags = TRUE, context_tags = FALSE)
d
library(openxlsx)
write.xlsx(d, "gedownloadet.xlsx")
library(tidyverse)
tibble(a = c(1:3), b = c(1:3))
x <- tibble(a = c(1:3), b = c(1:3))
is.data.frame(x)
library(tidyverse)
library(collostructions)
kwic <- data.frame(lemma = c("lorem", "ipsum", "dolor"),
cxn   = c("causedmotion", "ditransitive", "ditransitive"))
kwic %>% group_by(cxn) %>% summarise(
Freq = n()
)
kwic %>% group_by(lemma, cxn) %>% summarise(
Freq = n()
)
?collex.dist
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% str
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
)
kwic <- data.frame(lemma = c("lorem", "ipsum", "dolor"),
cxn   = c("causedmotion", "ditransitive", "ditransitive"))
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% collex.dist
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% str
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame %>% collex.dist
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame(stringsAsFactors = F) %>% collex.dist
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame(stringsAsFactors = F) %>% collex.dist(raw = T)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame() %>% collex.dist(raw = T)
library(tidyverse)
library(collostructions)
kwic <- data.frame(lemma = c("lorem", "ipsum", "dolor"),
cxn   = c("causedmotion", "ditransitive", "ditransitive"))
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% collex.dist
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% str
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% as.data.frame() %>% collex.dist(raw = T)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
)
kwic %>% group_by(cxn, lemma) %>% summarise(
Freq = n()
) %>% str
library(tidyverse)
tibble(a = c(1:3), b= c(3:5))
x <- tibble(a = c(1:3), b= c(3:5))
class(x)
x %>% summarise()
x %>% group_by(b) %>% summarise( n = n() )
x %>% group_by(b) %>% summarise( n = n() ) %>% class
kwic <- data.frame(lemma = c("lorem", "ipsum", "dolor"),
cxn   = c("causedmotion", "ditransitive", "ditransitive"))
kwic
kwic %>% group_by(lemma) %>% summarise(n = n())
kwic %>% group_by(lemma) %>% summarise(n = n()) %>% class
kwic %>% group_by(lemma) %>% summarise(n = n()) %>% str
kwic %>% group_by(lemma, cxn) %>% summarise(n = n()) %>% str
kwic %>% group_by(lemma, cxn) %>% summarise(n = n()) %>% class
libray(tidyverse)
kwic <- data.frame(lemma = c("lorem", "ipsum", "dolor"),
cxn   = c("causedmotion", "ditransitive", "ditransitive"))
kwic %>% group_by(lemma, cxn) %>% summarise(n = n() )
kwic %>% group_by(lemma, cxn) %>% summarise(n = n() ) %>% str
kwic %>% group_by(lemma, cxn) %>% summarise(n = n() ) %>% class
21+7+21+9+11+21+28
16+15+21+5+16+15+23+4
16+14+15+3+8+4+6
19+13+21+11+8+11+15+4
23+16+21+20+12+22+20+4
20+12+21+14+12+17+23+4
19+20+22+16+16+24+24+4
20+12+22+16+16+22+24+4
14+9+18+15+8+21+15+4
22+14+22+11+14+22+23+4
17+4+15+9+15+17+12+4
9+8+11+10+14+7+8
23+16+20+11+12+22+23+4
17+7+15+1+12+18+14+4
17+17+12+5+12+22+18+4
16+10+17+10+8+16+18+4
15+8+21+7+13+13+19+4
21+15+20+11+16+18+19+4
23+20+22+18+16+24+23+4
21+7+15+17+4+17+18+4
21+7+21+19+16+14+13+4
21+11+10+11+8+19+24+4
version(rlang)
package_version(rlang)
package_version("tidyverse")
?packageVersion
packageVersion(tidyverse)
packageVersion("tidyverse")
install.packages("rlang")
packageVersion("rlang")
lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))
install.packages("rlang")
.libPaths()
update.packages("rlang")
24*6
18*6
12*6
tmp <- installed.packages()
installedpkgs <- as.vector(tmp[is.na(tmp[,"Priority"]), 1])
save(installedpkgs, file="installed_old.rda")
readRDS("installed_old.rda")
load(file="installed_old.rda")
load("installed_old.rda")
tmp <- installed.packages()
tmp <- installed.packages()
installedpkgs.new <- as.vector(tmp[is.na(tmp[,"Priority"]), 1])
missing <- setdiff(installedpkgs, installedpkgs.new)
install.packages(missing)
library(devtools)
install_github("hartmast/wizard")
install_github("hartmast/concordances")
install.packages("/Users/stefanhartmann/Downloads/collostructions", repos = F)
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = F)
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = F, source = T)
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = NULL)
library(collostructions)
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = NULL)
library(collostructions)
library(collostructions)
library(wizard)
library(tidyverse)
remove.packages("collostructions")
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = NULL)
library(collostructions)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, ifelse(.Platform$OS.type == "windows", "Makevars.win", "Makevars"))
if (!file.exists(M)) file.create(M)
cat("\nCXX14FLAGS=-O3 -march=native -mtune=native",
if( grepl("^darwin", R.version$os)) "CXX14FLAGS += -arch x86_64 -ftemplate-depth-256" else
if (.Platform$OS.type == "windows") "CXX11FLAGS=-O3 -march=corei7 -mtune=corei7" else
"CXX14FLAGS += -fPIC",
file = M, sep = "\n", append = TRUE)
library("rstan") # observe startup messages
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7')
devtools::install_github("stan-dev/cmdstanr")
.libPaths()
library(collostructions)
update.packages(checkBuilt = T)
remove.packages("collostructions")
install.packages(file.choose(), repos = NULL)
library(collostructions)
remove.packages("collostructions")
install.packages("https://sfla.ch/wp-content/uploads/2020/06/collostructions_0.1.2.zip", repos = NULL)
install.packages("https://sfla.ch/wp-content/uploads/2020/06/collostructions_0.1.2.zip")
install.packages("https://sfla.ch/wp-content/uploads/2020/06/collostructions_0.1.2.zip", source = T)
install.packages("~/Downloads/collostructions_0.1.2.zip", repos = NULL, type = "win.binary")
install.packages("~/Downloads/collostructions.tar.gz", repos = NULL, type = "source")
library(collostructions)
?collex.dist
library(collostructions)
install.packages("https://sfla.ch/wp-content/uploads/2018/03/collostructions_0.1.0.tar.gz", repos = NULL)
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.0.tar.gz", repos = NULL)
library(collostructions)
library(collostructions)
?collex.covar
?collex.covar
library(collostructions)
?collex.covar
library(tidyverse)
?ggplot
?collex.covar
?collex.dist
citation("collostructions")
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tgz", repos = NULL)
library(collostructions)
library(collostructions)
library(collostructions)
?update.packages
install.packages("/Users/stefanhartmann/Downloads/collostructions_0.1.3.tar.gz", repos = NULL)
library(collostructions)
?collex.covar
?collex.covar
library(tidyverse)
?ggplot
library(collostructions)
?collex.covar
devtools::install_github("stan-dev/cmdstanr")
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
f <- alist(
y ~ dnorm( mu , sigma ),
mu ~ dnorm( 0 , 10 ),
sigma ~ dexp( 1 )
)
fit <- quap(
f ,
data=list(y=c(-1,1)) ,
start=list(mu=0,sigma=1)
)
fit
precis(fit)
install.packages("/Users/stefanhartmann/Documents/Statistik/Levshina2015/Rling_1.0.tar.gz", repos = NULL)
library(ngram)
?ngram
vignette(ngram)
vignette("ngram")
?vignette
library(keras)
install.packages("keras")
install.packages("quanteda")
library(keras)
skipgrams(sequence = "bla blubb blubb2")
skipgrams(sequence = "bla blubb blubb2", vocabulary_size = 3)
n
library(quanteda)
?tokens_ngrams
tokens_skipgrams("Das Pferd frisst keinen Gurkensalat")
tokens_skipgrams(unlist(strsplit("Das Pferd frisst keinen Gurkensalat", " ")))
tokens_ngrams(tokens(c("a b c d e", "c d e f g")), n = 2:3)
tokens_skipgrams(tokens(c("a b c d e", "c d e f g")), n = 2:3)
tokens_skipgrams(tokens(c("a b c d e", "c d e f g")), n = 2:3, skip = 2)
tokens_skipgrams(tokens(c("a b c d e", "c d e f g")), n = 2:3, skip = )
tokens_skipgrams(tokens(c("a b c d e", "c d e f g")), n = 2:3, skip = 1)
tokens_skipgrams(tokens(c("Das", "Pferd", "frisst", "keinen", "Gurkensalat")), n = 2:3, skip = 1)
tokens_skipgrams(tokens(c("Das Pferd frisst keinen Gurkensalat")), n = 2:3, skip = 1)
tokens_skipgrams(tokens(c("Das Pferd frisst keinen Gurkensalat")), n = 1:5, skip = 1)
tokens_skipgrams(tokens(c("Das Pferd frisst keinen Gurkensalat")), n = 1:5, skip = 0:1)
x <- tokens_skipgrams(tokens(c("Das Pferd frisst keinen Gurkensalat")), n = 1:5, skip = 0:1)
x
?tokens
as.character(x)
x <- as.character(x)
x
gsub("_", " [__] ", x)
x <- tokens_skipgrams(tokens(c("Das Pferd frisst keinen Gurkensalat")), n = 1:5, skip = 1)
x <- as.character(x)
x
gsub("_", " X ", x)
library(MuMIn)
r.squaredGLMM()
?r.squaredGLMM
8*6
80*6
480*5
480*4
53/341
7302.92*3
68400*0.65
7302.92*2
6715.05*2
(3 * 44460) + (14605.84 * 3) + (13430.10 * 3)
80*12
45*45
75*45
3375+400
3375+500
44.45*2
90*52
setwd("/Users/stefanhartmann/sciebo/Tutorials/googledocs")
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
library(bookdown)
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
?render_book
?gitbook
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
getwd()
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
render_book()
render_book("index.Rmd")
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
library(bookdown)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
list.files()
?bookdown
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
# compile HTML book
bookdown::render_book("index.Rmd", "bookdown::gitbook", new_session = FALSE)
